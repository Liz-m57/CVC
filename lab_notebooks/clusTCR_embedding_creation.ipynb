{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300a37f5",
   "metadata": {
    "cell_id": "dfcb45a2-e13b-432d-885a-42bb3dd563a3",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "markdown",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ClusTCR clusters in Embedding Space\n",
    "ClusTCR (https://svalkiers.github.io/clusTCR/) is used to create clusters for a set of CDR3 sequences. The embeddings of those sequences are then created with CVC and plotted, colored by their corresponding clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b24f51",
   "metadata": {
    "cell_id": "5d9c47c0-6d9e-482d-b141-b891da650664",
    "deepnote_cell_height": 190.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1645287525442,
    "source_hash": "371d1002",
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romi/projects/preTCR\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7a5597-a0ae-4aa7-bcb4-62d219a76df2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e1f947",
   "metadata": {
    "cell_id": "00001-55732162-ceaf-44b6-b0f9-62861608b761",
    "deepnote_cell_height": 1117.875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2706,
    "execution_start": 1645287607716,
    "source_hash": "cc7135c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'plots/CDR3_data_plots'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ClusTCR\n",
    "from clustcr import datasets, Clustering, read_cdr3, metarepertoire\n",
    "\n",
    "SRC_DIR = \"cvc\"\n",
    "assert os.path.isdir(SRC_DIR), f\"Cannot find src dir: {SRC_DIR}\"\n",
    "sys.path.append(SRC_DIR)\n",
    "from cvc import model_utils\n",
    "from cvc import plot_utils\n",
    "from lab_notebooks.utils import TRANSFORMER, DEVICE, DATA_DIR\n",
    "MODEL_DIR = os.path.join(SRC_DIR, \"models\")\n",
    "sys.path.append(MODEL_DIR)\n",
    "\n",
    "FILT_EDIT_DIST = True\n",
    "PLOT_DIR = os.path.join(os.path.dirname(SRC_DIR), \"plots/CDR3_data_plots\")\n",
    "if not os.path.isdir(PLOT_DIR):\n",
    "    os.makedirs(PLOT_DIR)\n",
    "PLOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_dir = DATA_DIR + \"db_data_nuc_vj_genes_pub_priv.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "91758697"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "tcrb_data = pd.read_csv(data_dir, usecols=[\"Sequences\", \"Private_Public_label\"], engine=\"pyarrow\")\n",
    "\n",
    "# drop duplicates\n",
    "tcrb_data.drop_duplicates(inplace=True)\n",
    "len(tcrb_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Different Embedding Visualizations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "training_data_dir = DATA_DIR + \"db_5mil_training_data_2.5Mpub_2.5Mpriv.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "86758697"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove sequences from tcrb_data that are in training_seqs\n",
    "training_seqs = pd.read_csv(training_data_dir, usecols=[\"Sequences\"])\n",
    "tcrb_data_sample_from = tcrb_data[~tcrb_data['Sequences'].isin(training_seqs['Sequences'])]\n",
    "len(tcrb_data_sample_from)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7999/2020802387.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tcrb_data_sample_from.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "86758697"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "tcrb_data_sample_from.drop_duplicates(inplace=True)\n",
    "len(tcrb_data_sample_from)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# sample 1,000,000 rows\n",
    "tcrb_data_sample = tcrb_data_sample_from.sample(n=1000000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ClusTCR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 10000 TCRs using two-step approach.\n",
      "Total time to run ClusTCR: 0.350s\n"
     ]
    }
   ],
   "source": [
    "cdr3 = tcrb_data_sample['Sequences']\n",
    "# recommended to use method mcl for data sets containing < 50,000 CDR3 sequences, and two-step for all data sets with > 50,000 sequences. \n",
    "clustering = Clustering(method='two-step')\n",
    "output = clustering.fit(cdr3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   size                motif\n0     2    CASRV[RT]GGIDTQYF\n1     2     CASSLER[IK]SPLHF\n2     2    CSVEEAGG[RI]YEQYF\n3     2    CSARGGLAG[AG]QQFF\n4     2     CASS[QM]LGPYGYTF\n5     2  CASSYSIS[RV]GNTEAFF",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>motif</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>CASRV[RT]GGIDTQYF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CASSLER[IK]SPLHF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>CSVEEAGG[RI]YEQYF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>CSARGGLAG[AG]QQFF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>CASS[QM]LGPYGYTF</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>CASSYSIS[RV]GNTEAFF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view output\n",
    "a = output.summary()\n",
    "# a[a.cluster_idx == 277]\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# look at the sizes of the clusters\n",
    "sns.histplot(\n",
    "    data=output.clusters_df, x='cluster', bins=output.clusters_df.cluster.max())\n",
    "len(output.clusters_df), output.clusters_df.groupby('cluster').size().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Embeedings on top 20 clusters (by size)\n",
    "##### Does the embedding space preserve the distances between the CDR3 sequences used by clusTCR?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sorted_output = output.summary().sort_values(by='size', ascending=False)\n",
    "top_20_sorted = sorted_output.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "top_20_sorted['cluster_idx'] = top_20_sorted.index\n",
    "# take the largest 20 clusters from output\n",
    "largest_20_clusters = output.clusters_df[output.clusters_df.cluster.isin(top_20_sorted['cluster_idx'])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'isspace'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m tcrb_embeddings \u001B[38;5;241m=\u001B[39m embedding_wrapper(largest_20_clusters[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjunction_aa\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m tcrb_embeddings\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m----> 6\u001B[0m tcrb_embeddings_adata \u001B[38;5;241m=\u001B[39m \u001B[43membedding_wrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_adata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtcrb_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlargest_20_clusters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m tcrb_embeddings_adata\u001B[38;5;241m.\u001B[39mplot_embedding(tcrb_embeddings_adata, color_embed\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcluster\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      8\u001B[0m                                 color_map\u001B[38;5;241m=\u001B[39mplt\u001B[38;5;241m.\u001B[39mget_cmap(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtab20\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m      9\u001B[0m                                 title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTop 20 clusTCR Clusters in Embedding Space\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m                                 legend_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, PLOT_DIR\u001B[38;5;241m=\u001B[39mPLOT_DIR, plot_pdf_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclusTCR_umap_2.5_mil_model.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/projects/preTCR/lab_notebooks/embbeding_wrapper.py:26\u001B[0m, in \u001B[0;36mEmbeddingWrapper.create_adata\u001B[0;34m(self, sequences, obs)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_adata\u001B[39m(\u001B[38;5;28mself\u001B[39m, sequences, obs):\n\u001B[0;32m---> 26\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msequences\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m     adata \u001B[38;5;241m=\u001B[39m ad\u001B[38;5;241m.\u001B[39mAnnData(embeddings, obs\u001B[38;5;241m=\u001B[39mobs)\n\u001B[1;32m     28\u001B[0m     sc\u001B[38;5;241m.\u001B[39mpp\u001B[38;5;241m.\u001B[39mpca(adata, n_comps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n",
      "File \u001B[0;32m~/projects/preTCR/lab_notebooks/embbeding_wrapper.py:19\u001B[0m, in \u001B[0;36mEmbeddingWrapper.__call__\u001B[0;34m(self, sequences)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, sequences):\n\u001B[0;32m---> 19\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_transformer_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings\n",
      "File \u001B[0;32m~/projects/preTCR/tcr/model_utils.py:415\u001B[0m, in \u001B[0;36mget_transformer_embeddings\u001B[0;34m(model_dir, seqs, seq_pair, layers, method, batch_size, device, pbar)\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;124;03mGet the embeddings for the given sequences from the given layers\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;124;03mLayers should be given as negative integers, where -1 indicates the last\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;124;03mand concatenate across layers\u001B[39;00m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    414\u001B[0m device \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_device(device)\n\u001B[0;32m--> 415\u001B[0m seqs \u001B[38;5;241m=\u001B[39m [s \u001B[38;5;28;01mif\u001B[39;00m ft\u001B[38;5;241m.\u001B[39mis_whitespaced(s) \u001B[38;5;28;01melse\u001B[39;00m ft\u001B[38;5;241m.\u001B[39minsert_whitespace(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m seqs]\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     tok \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mget_pretrained_bert_tokenizer(model_dir)\n",
      "File \u001B[0;32m~/projects/preTCR/tcr/model_utils.py:415\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;124;03mGet the embeddings for the given sequences from the given layers\u001B[39;00m\n\u001B[1;32m    402\u001B[0m \u001B[38;5;124;03mLayers should be given as negative integers, where -1 indicates the last\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;124;03mand concatenate across layers\u001B[39;00m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    414\u001B[0m device \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_device(device)\n\u001B[0;32m--> 415\u001B[0m seqs \u001B[38;5;241m=\u001B[39m [s \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mft\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_whitespaced\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m ft\u001B[38;5;241m.\u001B[39minsert_whitespace(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m seqs]\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     tok \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mget_pretrained_bert_tokenizer(model_dir)\n",
      "File \u001B[0;32m~/projects/preTCR/tcr/featurization.py:311\u001B[0m, in \u001B[0;36mis_whitespaced\u001B[0;34m(seq)\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;124;03mReturn whether the sequence has whitespace inserted\u001B[39;00m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;124;03m>>> is_whitespaced(\"R K D E S\")\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;124;03mTrue\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    310\u001B[0m tok \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(seq)\n\u001B[0;32m--> 311\u001B[0m spaces \u001B[38;5;241m=\u001B[39m [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tok \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39misspace()]\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(spaces) \u001B[38;5;241m==\u001B[39m floor(\u001B[38;5;28mlen\u001B[39m(seq) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/preTCR/tcr/featurization.py:311\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;124;03mReturn whether the sequence has whitespace inserted\u001B[39;00m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;124;03m>>> is_whitespaced(\"R K D E S\")\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;124;03mTrue\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    310\u001B[0m tok \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(seq)\n\u001B[0;32m--> 311\u001B[0m spaces \u001B[38;5;241m=\u001B[39m [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tok \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misspace\u001B[49m()]\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(spaces) \u001B[38;5;241m==\u001B[39m floor(\u001B[38;5;28mlen\u001B[39m(seq) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.float64' object has no attribute 'isspace'"
     ]
    }
   ],
   "source": [
    "# create and display embeddings #TODO\n",
    "from lab_notebooks import embbeding_wrapper as EW\n",
    "embedding_wrapper = EW.EmbeddingWrapper(TRANSFORMER, DEVICE, method=\"mean\", layers=[-1])\n",
    "tcrb_embeddings = embedding_wrapper(largest_20_clusters['junction_aa'])\n",
    "tcrb_embeddings.shape\n",
    "tcrb_embeddings_adata = embedding_wrapper.create_adata(tcrb_embeddings, largest_20_clusters)\n",
    "tcrb_embeddings_adata.plot_embedding(tcrb_embeddings_adata, color_embed='cluster',\n",
    "                                color_map=plt.get_cmap('tab20'),\n",
    "                                title=\"Top 20 clusTCR Clusters in Embedding Space\",\n",
    "                                legend_size=3, PLOT_DIR=PLOT_DIR, plot_pdf_path=\"clusTCR_umap_2.5_mil_model.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "0       CASRVRGGIDTQYF\n1       CASRVTGGIDTQYF\n2        CASSLERISPLHF\n3        CASSLERKSPLHF\n4       CSVEEAGGIYEQYF\n5       CSVEEAGGRYEQYF\n6       CSARGGLAGAQQFF\n7       CSARGGLAGGQQFF\n8        CASSMLGPYGYTF\n9        CASSQLGPYGYTF\n10    CASSYSISRGNTEAFF\n11    CASSYSISVGNTEAFF\nName: junction_aa, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_20_clusters['junction_aa']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cvc.embbeding_wrapper import EmbeddingWrapper\n",
    "largest_20_clusters.loc[:, 'Sequences'] = largest_20_clusters['junction_aa']\n",
    "\n",
    "# Create embeddings\n",
    "embed_wrap = EmbeddingWrapper(TRANSFORMER, DEVICE, largest_20_clusters, batch_size=1024, method=\"mean\", layers=[-1])\n",
    "embed_wrap.embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot embeddings\n",
    "embed_wrap.plot_embedding(\n",
    "    color_embed='cluster',\n",
    "    color_map=plt.get_cmap('tab20'),\n",
    "    title=\"Top 20 clusTCR Clusters in Embedding Space\",\n",
    "    legend_size=3,\n",
    "    plot_pdf_path=os.path.join(PLOT_DIR, \"clusTCR_umap_2.5_mil_model.pdf\"),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cef408d8-9130-407c-bfc8-1126d6b70d18",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}