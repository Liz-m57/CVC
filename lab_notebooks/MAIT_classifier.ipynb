{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary Classification of MAIT/iNKT Cells\n",
    "Classify cell type (MAIT/iNKT) of a given CDR3 sequence using different machine/deep learning models and compare the results.\n",
    "The input CDR3 sequences are either embedded using CVC or converted to one-hot encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563a8d23-e24b-4cb5-8cea-5c6f52f66473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romi/projects/cvc\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131cbe9c-6069-4645-b71f-7bb33715697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91824dd6-d4fd-44d9-8354-f219b37f075b",
   "metadata": {
    "cell_id": "00001-55732162-ceaf-44b6-b0f9-62861608b761",
    "deepnote_cell_height": 1117.875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2706,
    "execution_start": 1645287607716,
    "source_hash": "cc7135c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'plots/CDR3_data_plots'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import collections\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import lab_notebooks.utils\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SRC_DIR = \"cvc\"\n",
    "assert os.path.isdir(SRC_DIR), f\"Cannot find src dir: {SRC_DIR}\"\n",
    "sys.path.append(SRC_DIR)\n",
    "from cvc import model_utils\n",
    "from lab_notebooks.utils import SC_TRANSFORMER, TRANSFORMER, DEVICE, DATA_DIR\n",
    "MODEL_DIR = os.path.join(SRC_DIR, \"models\")\n",
    "sys.path.append(MODEL_DIR)\n",
    "\n",
    "FILT_EDIT_DIST = True\n",
    "\n",
    "PLOT_DIR = os.path.join(os.path.dirname(SRC_DIR), \"plots/CDR3_data_plots\")\n",
    "if not os.path.isdir(PLOT_DIR):\n",
    "    os.makedirs(PLOT_DIR)\n",
    "PLOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fba0ce0b",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# to load the embeddings from csv\n",
    "load_csv = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# load data, make sure to have V/J Gene of CDR3 sequence - below the data came from different datasets\n",
    "# https:/ls e/www.10xgenomics.com/resources/datasets/nsclc-tumor-tcr-enrichment-from-amplified-c-dna-1-standard-2-2-0\n",
    "data_dir_1 = DATA_DIR + \"10x_nsclc_tra_trb_df.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/20-k-bone-marrow-mononuclear-cells-bmmn-cs-5-ht-v-2-0-2-high-6-1-0\n",
    "data_dir_2 = DATA_DIR + \"20k_BMMNC_vdj_t_filtered_contig_annotations.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/pbm-cs-of-a-healthy-donor-tcr-enrichment-from-amplified-c-dna-1-standard-3-0-0\n",
    "data_dir_3 = DATA_DIR + \"pbmc2_t_filtered_contig_annotations.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/10-k-human-pbm-cs-5-v-2-0-chromium-x-2-standard-6-1-0\n",
    "data_dir_4 = DATA_DIR + \"10k_pbmc_vdj_t_filtered_contig_annotations.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-1-1-standard-3-0-2\n",
    "data_dir_5 = DATA_DIR + \"cd8_t_filtered_contig_annotations_d1.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-2-1-standard-3-0-2\n",
    "data_dir_6 = DATA_DIR + \"cd8_t_filtered_contig_annotations_d2.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-3-1-standard-3-0-2\n",
    "data_dir_7 = DATA_DIR + \"cd8_t_filtered_contig_annotations_d3.csv\"\n",
    "# https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-4-1-standard-3-0-2\n",
    "data_dir_8 = DATA_DIR + \"cd8_t_filtered_contig_annotations_d4.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def sc_load_data(data_dir):\n",
    "    sc_data = pd.read_csv(data_dir, usecols=[\"barcode\", \"contig_id\", \"chain\", \"v_gene\", \"j_gene\", \"c_gene\", \"cdr3\", \"cdr3_nt\"], engine=\"pyarrow\")\n",
    "    sc_data = sc_data[sc_data.cdr3 != \"None\"]\n",
    "    return sc_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7f68021-d2be-4beb-8bc0-a220e8bd41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "sc_data_1 = sc_load_data(data_dir_1)\n",
    "sc_data_2 = sc_load_data(data_dir_2)\n",
    "sc_data_3 = sc_load_data(data_dir_3)\n",
    "sc_data_4 = sc_load_data(data_dir_4)\n",
    "sc_data_5 = sc_load_data(data_dir_5)\n",
    "sc_data_6 = sc_load_data(data_dir_6)\n",
    "sc_data_7 = sc_load_data(data_dir_7)\n",
    "sc_data_8 = sc_load_data(data_dir_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(3643, 19737, 6037, 14632, 123862, 191643, 321467, 233142)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sc_data_1), len(sc_data_2), len(sc_data_3), len(sc_data_4), len(sc_data_5), len(sc_data_6), len(sc_data_7), len(sc_data_8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocess Data - Label MAIT/iNKT Cells"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "MAIT_v_gene='TRAV1-2'\n",
    "MAIT_j_gene = ['TRAJ33', 'TRAJ20', 'TRAJ12']\n",
    "iNKT_v_gene = 'TRAV10'\n",
    "iNKT_j_gene = 'TRAJ18'\n",
    "\n",
    "v_gene_to_use = MAIT_v_gene #iNKT_v_gene\n",
    "j_gene_to_use = MAIT_j_gene #iNKT_j_gene\n",
    "cell_label_to_use = 'MAIT_cell'#'iNKT_cell'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def label_iNKT_MAIT(sc_df, v_gene_list, j_gene_list, cell_label):\n",
    "    cell_label_not = 'non-'+cell_label\n",
    "    sc_df_tra = sc_df[sc_df['chain'] == 'TRA']\n",
    "\n",
    "    # create \"MAIT_cell\" column if the v_gene is \"TRAV1-2\" and j_gene is TRAJ33 or TRAJ20 or TRAJ12\n",
    "    sc_df_tra[cell_label] = np.where((sc_df_tra['v_gene'] == v_gene_list) &\n",
    "                                     (sc_df_tra['j_gene'].str.contains('|'.join(j_gene_list))), cell_label, cell_label_not)\n",
    "\n",
    "    # extract the list of barcodes from the dataframe that are MAIT cells\n",
    "    true_label_barcodes = sc_df_tra[sc_df_tra[cell_label] == cell_label]['barcode'].tolist()\n",
    "\n",
    "    # create a column in embed_data that is MAIT_cell if the barcode is in the MAIT_barcodes list, and non-MAIT_cell otherwise\n",
    "    sc_df[cell_label] = np.where(sc_df['barcode'].isin(true_label_barcodes), cell_label, cell_label_not)\n",
    "    return sc_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5483/2974906851.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_df_tra[cell_label] = np.where((sc_df_tra['v_gene'] == v_gene_list) &\n",
      "/tmp/ipykernel_5483/2974906851.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_df_tra[cell_label] = np.where((sc_df_tra['v_gene'] == v_gene_list) &\n",
      "/tmp/ipykernel_5483/2974906851.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_df_tra[cell_label] = np.where((sc_df_tra['v_gene'] == v_gene_list) &\n"
     ]
    }
   ],
   "source": [
    "sc_data_1_labeled = label_iNKT_MAIT(sc_data_1, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_2_labeled = label_iNKT_MAIT(sc_data_2, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_3_labeled = label_iNKT_MAIT(sc_data_3, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_4_labeled = label_iNKT_MAIT(sc_data_4, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_5_labeled = label_iNKT_MAIT(sc_data_5, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_6_labeled = label_iNKT_MAIT(sc_data_6, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_7_labeled = label_iNKT_MAIT(sc_data_7, v_gene_to_use, j_gene_to_use, cell_label_to_use)\n",
    "sc_data_8_labeled = label_iNKT_MAIT(sc_data_8, v_gene_to_use, j_gene_to_use, cell_label_to_use)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# take only TRB chains\n",
    "sc_data_1_labeled_TRB = sc_data_1_labeled[sc_data_1_labeled.chain == 'TRB']\n",
    "sc_data_2_labeled_TRB = sc_data_2_labeled[sc_data_2_labeled.chain == 'TRB']\n",
    "sc_data_3_labeled_TRB = sc_data_3_labeled[sc_data_3_labeled.chain == 'TRB']\n",
    "sc_data_4_labeled_TRB = sc_data_4_labeled[sc_data_4_labeled.chain == 'TRB']\n",
    "sc_data_5_labeled_TRB = sc_data_5_labeled[sc_data_5_labeled.chain == 'TRB']\n",
    "sc_data_6_labeled_TRB = sc_data_6_labeled[sc_data_6_labeled.chain == 'TRB']\n",
    "sc_data_7_labeled_TRB = sc_data_7_labeled[sc_data_7_labeled.chain == 'TRB']\n",
    "sc_data_8_labeled_TRB = sc_data_8_labeled[sc_data_8_labeled.chain == 'TRB']\n",
    "sc_data_all_labeled_TRB = pd.concat([sc_data_1_labeled_TRB, sc_data_2_labeled_TRB, sc_data_3_labeled_TRB, sc_data_4_labeled_TRB, sc_data_5_labeled_TRB, sc_data_6_labeled_TRB, sc_data_7_labeled_TRB, sc_data_8_labeled_TRB])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'non-MAIT_cell': 520358, 'MAIT_cell': 6493})"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(sc_data_all_labeled_TRB[cell_label_to_use])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "sc_data_all_labeled_TRB = sc_data_all_labeled_TRB.drop_duplicates(subset=['cdr3'])\n",
    "# drop nan\n",
    "sc_data_all_labeled_TRB = sc_data_all_labeled_TRB.dropna(subset=['cdr3'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'non-MAIT_cell': 122189, 'MAIT_cell': 2508})"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(sc_data_all_labeled_TRB[cell_label_to_use])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# export data\n",
    "sc_data_all_labeled_TRB.to_csv('./CDR3_data/sc_data_MAIT_TRB_8_datasets.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fb78feaa",
   "metadata": {},
   "source": [
    "#### Split cell-types into equal groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "cell_label = cell_label_to_use\n",
    "cell_label_not = 'non-'+cell_label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "cell_count = collections.Counter(sc_data_all_labeled_TRB[cell_label])[cell_label]\n",
    "NUM_TO_SAMPLE = cell_count\n",
    "# sample equal number of private and public\n",
    "if cell_label == 'MAIT_cell':\n",
    "    true_sample = sc_data_all_labeled_TRB.query('MAIT_cell == \"MAIT_cell\"').sample(NUM_TO_SAMPLE)\n",
    "    false_sample = sc_data_all_labeled_TRB.query('MAIT_cell == \"non-MAIT_cell\"').sample(NUM_TO_SAMPLE)\n",
    "else:\n",
    "    true_sample = sc_data_all_labeled_TRB.query('iNKT_cell == \"iNKT_cell\"').sample(NUM_TO_SAMPLE)\n",
    "    false_sample = sc_data_all_labeled_TRB.query('iNKT_cell == \"non-iNKT_cell\"').sample(NUM_TO_SAMPLE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                    barcode                     contig_id chain    v_gene  \\\n64350    GGAACTTGTCTGCGGT-5   GGAACTTGTCTGCGGT-5_contig_4   TRB   TRBV7-9   \n20087   ACCGTAAGTACACCGC-34  ACCGTAAGTACACCGC-34_contig_1   TRB   TRBV4-2   \n9572    AAGCCGCAGTAGTGCG-20  AAGCCGCAGTAGTGCG-20_contig_2   TRB    TRBV30   \n37069    AGATCTGGTTGGTTTG-9   AGATCTGGTTGGTTTG-9_contig_2   TRB  TRBV20-1   \n11894    GCATGATAGGCCGAAT-1   GCATGATAGGCCGAAT-1_contig_2   TRB    TRBV30   \n...                     ...                           ...   ...       ...   \n33865    ATCGAGTTCATGTAGC-3   ATCGAGTTCATGTAGC-3_contig_4   TRB   TRBV6-1   \n51019   CATCCACGTTCCGTCT-35  CATCCACGTTCCGTCT-35_contig_1   TRB     TRBV9   \n115496   TCCCGATCATGATCCA-2   TCCCGATCATGATCCA-2_contig_3   TRB  TRBV20-1   \n57339   CCGGGATGTAGCACGA-37  CCGGGATGTAGCACGA-37_contig_2   TRB    TRBV28   \n176918   CAGATCACAGTCCTTC-4   CAGATCACAGTCCTTC-4_contig_3   TRB   TRBV4-1   \n\n         j_gene c_gene                cdr3  \\\n64350   TRBJ2-7  TRBC2      CASSVAGLLYEQYF   \n20087   TRBJ1-5  TRBC1  CASSHPPGADLGGQPQHF   \n9572    TRBJ1-5  TRBC1    CAWSVPPVQGDRTQHF   \n37069   TRBJ1-2  TRBC1     CSARDLDSLTNGYTF   \n11894   TRBJ2-3  TRBC2       CAWSGEPSQAQYF   \n...         ...    ...                 ...   \n33865   TRBJ1-6  TRBC1       CASTGENNSPLHF   \n51019   TRBJ2-2  TRBC2  CASSVDWSGPGNTGELFF   \n115496  TRBJ2-1  TRBC2     CSARALAGGTNEQFF   \n57339   TRBJ1-5  TRBC1      CASSFQGGDQPQHF   \n176918  TRBJ2-5  TRBC2     CASSQDMGSPETQYF   \n\n                                                  cdr3_nt      MAIT_cell  \n64350          TGTGCCAGCAGCGTCGCGGGACTCCTTTACGAGCAGTACTTC      MAIT_cell  \n20087   TGTGCCAGCAGCCACCCCCCGGGAGCGGATCTGGGGGGTCAGCCCC...      MAIT_cell  \n9572     TGTGCCTGGAGTGTACCCCCCGTCCAGGGGGATCGGACCCAGCATTTT      MAIT_cell  \n37069       TGCAGTGCTAGAGATCTGGACAGCCTTACGAATGGCTACACCTTC      MAIT_cell  \n11894             TGTGCCTGGAGTGGGGAACCTAGCCAGGCGCAGTATTTT      MAIT_cell  \n...                                                   ...            ...  \n33865             TGTGCCAGCACTGGCGAAAATAATTCACCCCTCCACTTT  non-MAIT_cell  \n51019   TGTGCCAGCAGCGTAGATTGGTCAGGGCCAGGGAACACCGGGGAGC...  non-MAIT_cell  \n115496      TGCAGTGCTAGAGCTCTAGCGGGGGGGACAAATGAGCAGTTCTTC  non-MAIT_cell  \n57339          TGTGCCAGCAGTTTTCAAGGAGGAGATCAGCCCCAGCATTTT  non-MAIT_cell  \n176918      TGCGCCAGCAGCCAAGATATGGGGTCTCCAGAGACCCAGTACTTC  non-MAIT_cell  \n\n[5016 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>barcode</th>\n      <th>contig_id</th>\n      <th>chain</th>\n      <th>v_gene</th>\n      <th>j_gene</th>\n      <th>c_gene</th>\n      <th>cdr3</th>\n      <th>cdr3_nt</th>\n      <th>MAIT_cell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64350</th>\n      <td>GGAACTTGTCTGCGGT-5</td>\n      <td>GGAACTTGTCTGCGGT-5_contig_4</td>\n      <td>TRB</td>\n      <td>TRBV7-9</td>\n      <td>TRBJ2-7</td>\n      <td>TRBC2</td>\n      <td>CASSVAGLLYEQYF</td>\n      <td>TGTGCCAGCAGCGTCGCGGGACTCCTTTACGAGCAGTACTTC</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>20087</th>\n      <td>ACCGTAAGTACACCGC-34</td>\n      <td>ACCGTAAGTACACCGC-34_contig_1</td>\n      <td>TRB</td>\n      <td>TRBV4-2</td>\n      <td>TRBJ1-5</td>\n      <td>TRBC1</td>\n      <td>CASSHPPGADLGGQPQHF</td>\n      <td>TGTGCCAGCAGCCACCCCCCGGGAGCGGATCTGGGGGGTCAGCCCC...</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>9572</th>\n      <td>AAGCCGCAGTAGTGCG-20</td>\n      <td>AAGCCGCAGTAGTGCG-20_contig_2</td>\n      <td>TRB</td>\n      <td>TRBV30</td>\n      <td>TRBJ1-5</td>\n      <td>TRBC1</td>\n      <td>CAWSVPPVQGDRTQHF</td>\n      <td>TGTGCCTGGAGTGTACCCCCCGTCCAGGGGGATCGGACCCAGCATTTT</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>37069</th>\n      <td>AGATCTGGTTGGTTTG-9</td>\n      <td>AGATCTGGTTGGTTTG-9_contig_2</td>\n      <td>TRB</td>\n      <td>TRBV20-1</td>\n      <td>TRBJ1-2</td>\n      <td>TRBC1</td>\n      <td>CSARDLDSLTNGYTF</td>\n      <td>TGCAGTGCTAGAGATCTGGACAGCCTTACGAATGGCTACACCTTC</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>11894</th>\n      <td>GCATGATAGGCCGAAT-1</td>\n      <td>GCATGATAGGCCGAAT-1_contig_2</td>\n      <td>TRB</td>\n      <td>TRBV30</td>\n      <td>TRBJ2-3</td>\n      <td>TRBC2</td>\n      <td>CAWSGEPSQAQYF</td>\n      <td>TGTGCCTGGAGTGGGGAACCTAGCCAGGCGCAGTATTTT</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33865</th>\n      <td>ATCGAGTTCATGTAGC-3</td>\n      <td>ATCGAGTTCATGTAGC-3_contig_4</td>\n      <td>TRB</td>\n      <td>TRBV6-1</td>\n      <td>TRBJ1-6</td>\n      <td>TRBC1</td>\n      <td>CASTGENNSPLHF</td>\n      <td>TGTGCCAGCACTGGCGAAAATAATTCACCCCTCCACTTT</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>51019</th>\n      <td>CATCCACGTTCCGTCT-35</td>\n      <td>CATCCACGTTCCGTCT-35_contig_1</td>\n      <td>TRB</td>\n      <td>TRBV9</td>\n      <td>TRBJ2-2</td>\n      <td>TRBC2</td>\n      <td>CASSVDWSGPGNTGELFF</td>\n      <td>TGTGCCAGCAGCGTAGATTGGTCAGGGCCAGGGAACACCGGGGAGC...</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>115496</th>\n      <td>TCCCGATCATGATCCA-2</td>\n      <td>TCCCGATCATGATCCA-2_contig_3</td>\n      <td>TRB</td>\n      <td>TRBV20-1</td>\n      <td>TRBJ2-1</td>\n      <td>TRBC2</td>\n      <td>CSARALAGGTNEQFF</td>\n      <td>TGCAGTGCTAGAGCTCTAGCGGGGGGGACAAATGAGCAGTTCTTC</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>57339</th>\n      <td>CCGGGATGTAGCACGA-37</td>\n      <td>CCGGGATGTAGCACGA-37_contig_2</td>\n      <td>TRB</td>\n      <td>TRBV28</td>\n      <td>TRBJ1-5</td>\n      <td>TRBC1</td>\n      <td>CASSFQGGDQPQHF</td>\n      <td>TGTGCCAGCAGTTTTCAAGGAGGAGATCAGCCCCAGCATTTT</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>176918</th>\n      <td>CAGATCACAGTCCTTC-4</td>\n      <td>CAGATCACAGTCCTTC-4_contig_3</td>\n      <td>TRB</td>\n      <td>TRBV4-1</td>\n      <td>TRBJ2-5</td>\n      <td>TRBC2</td>\n      <td>CASSQDMGSPETQYF</td>\n      <td>TGCGCCAGCAGCCAAGATATGGGGTCTCCAGAGACCCAGTACTTC</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n  </tbody>\n</table>\n<p>5016 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join public and private samples\n",
    "cell_type_data_sample = pd.concat([true_sample, false_sample])\n",
    "cell_type_data_sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAIT_cell' 'MAIT_cell' 'MAIT_cell' ... 'non-MAIT_cell' 'non-MAIT_cell'\n",
      " 'non-MAIT_cell']\n"
     ]
    }
   ],
   "source": [
    "# convert label column to numpy array\n",
    "cell_label_array = cell_type_data_sample[cell_label].to_numpy()\n",
    "print(cell_label_array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# rename cdr3 column to Sequences for embedding creation\n",
    "cell_type_data_sample.rename(columns={\"cdr3\": \"Sequences\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/romi/projects/cvc/output_5mil_even_priv_pub were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ee6797d4e894565a4c924fc75993d14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(5016, 768)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cvc.embbeding_wrapper import EmbeddingWrapper\n",
    "# Create embeddings\n",
    "embed_wrap = EmbeddingWrapper(TRANSFORMER, DEVICE, sequences_df=cell_type_data_sample, batch_size=256, method=\"mean\", layers=[-1], pbar=True, max_len=64)\n",
    "embed_wrap.embeddings.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tcrbert/lib/python3.9/site-packages/anndata/_core/anndata.py:119: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "# create anndata object\n",
    "embeddings_adata = embed_wrap.create_anndata()\n",
    "# embeddings df\n",
    "df_embeddings = pd.DataFrame(embed_wrap.embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# add MAIT label to dataframe\n",
    "df_embeddings_with_label = df_embeddings\n",
    "df_embeddings_with_label[cell_label]=list(embeddings_adata.obs[cell_label])\n",
    "df_embeddings_with_label['Sequences']=list(embeddings_adata.obs['Sequences'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "file_embedding_path = './' + cell_label + '_data_embeddings_8_datasets.csv'\n",
    "# export embeddings to csvֿ\n",
    "df_embeddings_with_label.to_csv(DATA_DIR + file_embedding_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# load from csv\n",
    "if load_csv==True:\n",
    "    df_embeddings_with_label = pd.read_csv(\"./CDR3_data/MAIT_cell_data_embeddings_8_datasets.csv\")\n",
    "    df_embeddings_with_label = df_embeddings_with_label.drop_duplicates(subset=['Sequences'])\n",
    "    # remove Public_Private_Label column\n",
    "    # df_embeddings_with_label = df_embeddings_with_label.drop(columns=['Public_Private_Label'])\n",
    "cell_type_embeddings = df_embeddings_with_label.iloc[:,1:-2].to_numpy()\n",
    "cell_type_label_array= df_embeddings_with_label.MAIT_cell.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({'MAIT_cell': 2508, 'non-MAIT_cell': 2508})"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates Sequences\n",
    "df_embeddings_with_label = df_embeddings_with_label.drop_duplicates(subset=['Sequences'])\n",
    "collections.Counter(df_embeddings_with_label.MAIT_cell)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Binary Classification Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "def split_train_test(embeddings, embedding_labels):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    # The data will be divided into 80% training 20% validation\n",
    "    idx_train = int(len(embeddings) * TRAIN_RATIO)\n",
    "\n",
    "    indices = np.arange(embeddings.shape[0])\n",
    "\n",
    "    # Shuffle data\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Separate the images and the labels\n",
    "    embeddings_shuffle = embeddings[indices] \n",
    "    embedding_labels_shuffle = embedding_labels[indices]\n",
    "\n",
    "    # Split to train and validation\n",
    "    train_embeddings = embeddings_shuffle[:idx_train]\n",
    "    train_labels = embedding_labels_shuffle[:idx_train]\n",
    "    validation_embeddings = embeddings_shuffle[idx_train:]\n",
    "    validation_labels = embedding_labels_shuffle[idx_train:]\n",
    "    \n",
    "    return train_embeddings, train_labels, validation_embeddings, validation_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings: (5016, 768)\n",
      "shape of embedding_labels: (5016,)\n"
     ]
    }
   ],
   "source": [
    "embeddings = cell_type_embeddings\n",
    "embedding_labels = cell_type_label_array\n",
    "print(\"shape of embeddings: {}\\nshape of embedding_labels: {}\".format(embeddings.shape,embedding_labels.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "((4012, 768), (4012,), (1004, 768), (1004,))"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings, embed_train_labels, validation_embeddings, embed_validation_labels = split_train_test(embeddings, embedding_labels)\n",
    "train_embeddings.shape, embed_train_labels.shape, validation_embeddings.shape, embed_validation_labels.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "labels = [cell_label, cell_label_not]\n",
    "label_to_id = {label: i for i, label in enumerate(labels)}\n",
    "numeric_train_labels = [label_to_id[label] for label in embed_train_labels]\n",
    "numeric_valid_labels = [label_to_id[label] for label in embed_validation_labels]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(Counter({1: 524, 0: 480}), Counter({0: 2028, 1: 1984}))"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the data is even\n",
    "collections.Counter(numeric_valid_labels), collections.Counter(numeric_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### One-Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# Import Dependencies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to encode sequences\n",
    "def encode_seq(sequence, max_cdr3_len):\n",
    "    alphabet = ['A', 'C', 'D', 'E', 'F', 'G','H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', \"*\"]\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    integer_encoded = [char_to_int[char] for char in sequence]\n",
    "    \n",
    "    # one hot encode\n",
    "    integer_encoded = torch.tensor(integer_encoded)\n",
    "    integer_encoded = F.one_hot(integer_encoded, num_classes=len(alphabet))\n",
    "    \n",
    "    # pad integer_encoded tensor first dim with zeros up to max_cdr3_len\n",
    "    integer_encoded = F.pad(integer_encoded, (0,0,0, max_cdr3_len - len(integer_encoded)))\n",
    "    \n",
    "    integer_encoded = integer_encoded.numpy()\n",
    "\n",
    "    return integer_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract sequences\n",
    "cdr3_sequences = df_embeddings_with_label['Sequences']#tcrb_data_sample['Sequences']\n",
    "sequences_labels = cell_type_label_array\n",
    "max_cdr3_len = cdr3_sequences.apply(len).max()\n",
    "max_cdr3_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training set: (876,)\n",
      "shape of validation set: (220,)\n"
     ]
    }
   ],
   "source": [
    "# split data into train/test\n",
    "train_seqs, train_labels, validation_seqs, validation_labels = split_train_test(cdr3_sequences.to_numpy(), sequences_labels)\n",
    "print(\"shape of training set: {}\\nshape of validation set: {}\".format(train_seqs.shape, validation_seqs.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "numeric_train_onehot_labels = [label_to_id[label] for label in train_labels]\n",
    "numeric_valid_onehot_labels = [label_to_id[label] for label in validation_labels]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# encode amino acid sequences to one hot vector\n",
    "encoded_train_seqs = pd.Series(train_seqs).apply(lambda x: encode_seq(x, max_cdr3_len))\n",
    "encoded_validation_seqs = pd.Series(validation_seqs).apply(lambda x: encode_seq(x, max_cdr3_len))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "((876, 22, 21), (220, 22, 21))"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack list(encoded_train_seqs) in dim 0\n",
    "train_seqs_stack = np.stack(encoded_train_seqs, axis=0)\n",
    "valid_seqs_stack = np.stack(encoded_validation_seqs, axis=0)\n",
    "train_seqs_stack.shape, valid_seqs_stack.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "((876, 462), (220, 462))"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape train/validation tensors\n",
    "train_seqs_stack = train_seqs_stack.reshape(train_seqs_stack.shape[0], -1)\n",
    "valid_seqs_stack = valid_seqs_stack.reshape(valid_seqs_stack.shape[0], -1)\n",
    "train_seqs_stack.shape, valid_seqs_stack.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### xgBoost on Embeddings\n",
    "Guide on xgBoost - https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_embeddings = sc.fit_transform(train_embeddings)\n",
    "validation_embeddings = sc.fit_transform(validation_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract accuracy\n",
    "accuracy_xgb, xgb_preds, xgb_classifier = \\\n",
    "    lab_notebooks.utils.xgb_classify(train_embeddings, numeric_train_labels, validation_embeddings, numeric_valid_labels)\n",
    "accuracy_xgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the roc curve for the model\n",
    "# get probabilities\n",
    "probs = xgb_classifier.predict_proba(validation_embeddings)\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(numeric_valid_labels, probs[:, 1])\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### xgBoost on One-Hot Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "77.27272727272727"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply xgb on onehot, extract accuracy\n",
    "accuracy_xgb_onehot, xgb_preds_onehot, xgb_classifier_onehot =\\\n",
    "    lab_notebooks.utils.xgb_classify(train_seqs_stack, numeric_train_onehot_labels, valid_seqs_stack, numeric_valid_onehot_labels)\n",
    "\n",
    "# get probabilities and roc\n",
    "probs = xgb_classifier_onehot.predict_proba(valid_seqs_stack)\n",
    "fpr_onehot_xgb, tpr_onehot_xgb, thresholds_onehot_xgb = roc_curve(numeric_valid_onehot_labels, probs[:, 1])\n",
    "roc_auc_onehot_xgb = auc(fpr_onehot_xgb, tpr_onehot_xgb)\n",
    "\n",
    "accuracy_xgb_onehot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# apply LDA\n",
    "accuracy_lda, lda_preds, lda_classifier = lab_notebooks.utils.lda_classify(train_embeddings,numeric_train_labels, validation_embeddings, numeric_valid_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "60.0"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the roc curve for the model\n",
    "# get probabilities\n",
    "probs = lda_classifier.predict_proba(validation_embeddings)\n",
    "fpr_lda, tpr_lda, thresholds_lda = roc_curve(numeric_valid_labels, probs[:, 1])\n",
    "roc_auc_lda = auc(fpr_lda, tpr_lda)\n",
    "\n",
    "accuracy_lda"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LDA oneHot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "77.27272727272727"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_lda_onehot, lda_preds_onehot, lda_classifier_onehot =\\\n",
    "    lab_notebooks.utils.xgb_classify(train_seqs_stack, numeric_train_onehot_labels, valid_seqs_stack, numeric_valid_onehot_labels)\n",
    "\n",
    "probs_oh_lda = lda_classifier_onehot.predict_proba(valid_seqs_stack)\n",
    "fpr_onehot_lda, tpr_onehot_lda, thresholds_onehot_lda = roc_curve(numeric_valid_onehot_labels, probs_oh_lda[:, 1])\n",
    "roc_auc_onehot_lda = auc(fpr_onehot_lda, tpr_onehot_lda)\n",
    "\n",
    "accuracy_lda_onehot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deep Learning Model on Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# set flag to run with onehot\n",
    "DNN_ONEHOT = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# defining dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dataset(Dataset):\n",
    "    def __init__(self,x, y):\n",
    "        # self.x = torch.tensor(x, dtype=torch.float32).to('cuda')\n",
    "        # self.y = torch.tensor(y, dtype=torch.float32).to('cuda')\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    "        assert self.x.shape[0] == self.y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# create datasets\n",
    "if DNN_ONEHOT==0:\n",
    "    trainset = dataset(train_embeddings, numeric_train_labels)\n",
    "    validset = dataset(validation_embeddings, numeric_valid_labels)\n",
    "else:\n",
    "    trainset = dataset(train_seqs_stack, numeric_train_onehot_labels)\n",
    "    validset = dataset(valid_seqs_stack, numeric_valid_onehot_labels)\n",
    "\n",
    "# DataLoader with 10 workers\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=10, pin_memory=True)\n",
    "validloader = DataLoader(validset, batch_size=BATCH_SIZE, num_workers=10, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# defining the network\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,128)\n",
    "        self.fc2 = nn.Linear(128,32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.00001\n",
    "\n",
    "# set input shape\n",
    "input_shape = train_embeddings.shape[1]\n",
    "if DNN_ONEHOT:\n",
    "    input_shape = train_seqs_stack.shape[1]\n",
    "\n",
    "# Model , Optimizer, Loss\n",
    "device = 'cpu'\n",
    "model = Net(input_shape=input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    y_test = y_test.unsqueeze(1)\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def train_classify(model, trainloader, optimizer):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for train_embedding, train_label in tqdm.notebook.tqdm(trainloader, total=len(trainloader)):\n",
    "        # option to move train_embedding, train_label to gpu here\n",
    "        # calculate output\n",
    "        train_embedding, train_label =  train_embedding.to(device), train_label.to(device)\n",
    "        output = model(train_embedding)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(output, train_label.reshape(-1,1))\n",
    "        \n",
    "        # accuracy\n",
    "        acc = calculate_accuracy(output, train_label)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        count += len(train_label)\n",
    "        \n",
    "    return epoch_loss / len(trainloader), epoch_acc / len(trainloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def evaluate_classify(model, validloader): \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    pred_label_list = []\n",
    "    with torch.no_grad(): \n",
    "        for valid_embedding, valid_label in tqdm.notebook.tqdm(validloader, total=len(validloader)):\n",
    "            # option to move valid_embedding, valid_label to gpu here\n",
    "            valid_embedding, valid_label = valid_embedding.to(device), valid_label.to(device)\n",
    "            # calculate output\n",
    "            output = model(valid_embedding)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_fn(output, valid_label.reshape(-1,1))\n",
    "\n",
    "            # accuracy\n",
    "            acc = calculate_accuracy(output, valid_label)\n",
    "            \n",
    "            # add to lists for confusion matrixv\n",
    "            label_list.append(valid_label.cpu())\n",
    "            pred_label_list.append(output.cpu())\n",
    "            \n",
    "            #acc = calculate_accuracy(output, valid_label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            count += len(valid_label)\n",
    "    return (epoch_loss / len(validloader), epoch_acc / len(validloader),\n",
    "            torch.cat(label_list, dim=0), \n",
    "            torch.cat(pred_label_list, dim=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "liveloss1_class = PlotLosses()\n",
    "logs_class = {}\n",
    "EPOCHS=150\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('starting epoch {}'.format(epoch))\n",
    "    train_loss, train_acc = train_classify(model, trainloader, optimizer)\n",
    "    print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, EPOCHS, train_loss))\n",
    "    \n",
    "    print('Epoch {} of {}, Train Accuracy: {:.3f}'.format(\n",
    "          epoch+1, EPOCHS, train_acc))\n",
    "    \n",
    "    logs_class['train loss'] = train_loss\n",
    "    logs_class['train accuracy'] = train_acc\n",
    "\n",
    "    valid_loss, valid_acc, label_list, pred_label_list  = evaluate_classify(model, validloader)\n",
    "    print('Epoch {} of {}, Validate Loss: {:.3f}'.format(\n",
    "        epoch+1, EPOCHS, valid_loss))\n",
    "    \n",
    "    print('Epoch {} of {}, Validate Accuracy: {:.3f}'.format(\n",
    "        epoch+1, EPOCHS, valid_acc))\n",
    "\n",
    "    logs_class['validation loss'] = valid_loss\n",
    "    logs_class['validation accuracy'] = valid_acc\n",
    "        \n",
    "    liveloss1_class.update(logs_class)\n",
    "    liveloss1_class.send()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Save model\n",
    "PATH = \"./classifiers/MAIT_classifier.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get predictions from model\n",
    "label_list = []\n",
    "pred_label_list = []\n",
    "_, _, label_list, pred_label_list = evaluate_classify(model, validloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds, labels = pred_label_list[:, 0].cpu().numpy(), label_list.unsqueeze(1)[:, 0].cpu().numpy()\n",
    "preds_at_threshold_05 = (preds > 0.5).astype(int)\n",
    "labels = labels.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate FN, TP, TN, FP \n",
    "tn_nn, fp_nn, fn_nn, tp_nn = confusion_matrix(preds_at_threshold_05, labels).ravel()\n",
    "\n",
    "labels_vals = [tn_nn, fp_nn, fn_nn, tp_nn]\n",
    "labels_TF = [f\"True Negative\",\"False Positive\",\"False Negative\",\"True Positive\"]\n",
    "sum_all = tn_nn + fp_nn + fn_nn + tp_nn\n",
    "\n",
    "labels_vals_str = [str(round(val/sum_all, 4)*100) for val in labels_vals]\n",
    "labels_TF_final = [f\"{label}\\n{label_val_str}%\" for label, label_val_str in zip(labels_TF, labels_vals_str)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_TF_final = [[labels_TF_final[0], labels_TF_final[1]], [labels_TF_final[2], labels_TF_final[3]]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate confusion matrix\n",
    "confusion_mat_val = confusion_matrix(preds_at_threshold_05, label_list.cpu().numpy())\n",
    "labels_TF = np.asarray(labels_TF).reshape(2,2)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(confusion_mat_val, annot=labels_TF_final, fmt=\"\", cmap='RdPu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# roc data for DNN\n",
    "if DNN_ONEHOT==0:\n",
    "    fpr_dnn, tpr_dnn, thresholds_dnn = roc_curve(embed_validation_labels, preds)\n",
    "    roc_auc_dnn = auc(fpr_dnn, tpr_dnn)\n",
    "else:\n",
    "    fpr_onehot_dnn, tpr_onehot_dnn, thresholds_onehot_dnn = roc_curve(validation_labels, preds)\n",
    "    roc_auc_onehot_dnn = auc(fpr_onehot_dnn, tpr_onehot_dnn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "{'DNN': 79.57133333333333, 'DNN_OneHot': 75.42399999999999}"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dic_1 = {'DNN': [81.43, 78.857, 78.427],\n",
    "             'DNN_OneHot': [71.429, 75.143, 79.7]}\n",
    "\n",
    "# calculate mean accuracy for each model\n",
    "res_dnn_avg = {key: np.mean(value) for key, value in dnn_dic_1.items()}\n",
    "res_dnn_avg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dictionary\n",
    "dnn_dic = {'model': ['DNN', 'DNN', 'DNN',\n",
    "                     'DNN_OneHot', 'DNN_OneHot', 'DNN_OneHot'],\n",
    "           'accuracy': [81.43, 78.857, 78.427, 71.429, 75.143, 79.7]}\n",
    "\n",
    "# barplot of accuracy with error bars\n",
    "df = pd.DataFrame(dnn_dic)\n",
    "df = df.sort_values(by='accuracy', ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "df\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='model', y='accuracy', data=df, ax=ax, palette=\"flare\", capsize=.2)\n",
    "# ax.set_title('Accuracy of different classification models')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(85, 100)\n",
    "# save figure in svg format in high resolution\n",
    "plt.savefig('./plots/cvc_2.0/accuracy_MAIT.svg', format='svg', dpi=1200)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
