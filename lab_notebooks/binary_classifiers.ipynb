{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Binary Classification Using Trained Models\n",
    "\n",
    "This notebooks enables to apply the trained models to new data. The trained models are saved in the folder \"trained_models\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Set the classification type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "CLASSIFICATION = 'PUBLIC_PRIVATE' #'MAIT'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/romi/projects/cvc\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "if CLASSIFICATION == 'MAIT':\n",
    "    CLASSIFICATION_MODEL_PATH = \"./classifiers/MAIT_classifier.pth\"\n",
    "    label = \"MAIT_cell\"\n",
    "else:\n",
    "    CLASSIFICATION_MODEL_PATH = \"./classifiers/private_public_classifier.pth\"\n",
    "    label = \"Public_Private_Label\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n0    -0.149587 -0.197047 -0.606274  0.246161  0.146642 -0.208196  0.247288   \n1    -0.003837  0.004939 -0.305185 -0.467737  0.554620  0.526504  0.037872   \n2     0.027054  0.238266  0.138490 -0.477724  0.421007  0.106373 -0.682291   \n3    -0.149578  0.100374 -0.122322 -0.478098  0.454484  0.019130  0.048994   \n4    -0.540540  0.291595 -0.353379 -0.261123  0.426946  0.357447 -0.488219   \n...        ...       ...       ...       ...       ...       ...       ...   \n5011 -0.329775  0.793744 -1.056300  0.181084  0.043187 -0.084797  0.497528   \n5012 -0.100326  0.304981  0.190182 -0.059698  0.107292  0.121101 -0.251405   \n5013 -0.056023 -0.094397 -0.433103 -0.062313  0.069507 -0.040174  0.057963   \n5014 -0.422617  0.676036 -1.092209  0.034845  0.449366  0.100408  0.365332   \n5015 -0.679665  0.381582 -0.096865 -0.755159  0.349162  0.068600 -0.496824   \n\n             7         8         9  ...       760       761       762  \\\n0    -0.079729  0.198015 -0.245093  ... -0.638298  0.011018 -0.319213   \n1    -0.058776  0.078017 -0.378901  ...  0.325271 -0.620283 -0.451306   \n2    -0.285417  0.483916 -0.346199  ...  0.507948 -0.131854  0.230915   \n3     0.235329  0.132402 -0.505863  ...  0.282709  0.410364  0.008110   \n4    -0.435053  0.388957 -0.267924  ...  0.328469 -0.103942  0.323352   \n...        ...       ...       ...  ...       ...       ...       ...   \n5011  0.468565  0.060517  0.038454  ... -0.269269 -0.119622 -0.516974   \n5012 -0.306332  0.125169 -0.237075  ... -0.172579 -0.399773 -0.378466   \n5013 -0.075291  0.027573 -0.167322  ... -0.157909  0.064306 -0.047353   \n5014  0.275192  0.020950  0.030260  ... -0.000810 -0.096166 -0.774795   \n5015 -0.169834  0.225958 -0.460315  ... -0.035289 -0.299447 -0.159665   \n\n           763       764       765       766       767           Sequences  \\\n0     0.780746 -0.412318  0.522235  0.514297  0.207887      CASSVAGLLYEQYF   \n1    -0.204477 -0.042363  0.488556  0.090419  0.102915  CASSHPPGADLGGQPQHF   \n2     0.139384 -0.132491  0.416187  0.232041 -0.580679    CAWSVPPVQGDRTQHF   \n3    -0.087051 -0.256943  0.420582 -0.317372  0.073733     CSARDLDSLTNGYTF   \n4     0.735837  0.272375  0.473237  0.894415 -0.243902       CAWSGEPSQAQYF   \n...        ...       ...       ...       ...       ...                 ...   \n5011  0.407369  0.187545  0.344213  0.109828  0.269770       CASTGENNSPLHF   \n5012  0.207969 -0.128755  0.727024  0.299680  0.027128  CASSVDWSGPGNTGELFF   \n5013  0.050179 -0.237840  0.765852 -0.496809  0.229118     CSARALAGGTNEQFF   \n5014  0.810294 -0.045002  0.009765  0.297485  0.518775      CASSFQGGDQPQHF   \n5015  0.281305 -0.450529  0.594555  0.529679 -0.038543     CASSQDMGSPETQYF   \n\n          MAIT_cell  \n0         MAIT_cell  \n1         MAIT_cell  \n2         MAIT_cell  \n3         MAIT_cell  \n4         MAIT_cell  \n...             ...  \n5011  non-MAIT_cell  \n5012  non-MAIT_cell  \n5013  non-MAIT_cell  \n5014  non-MAIT_cell  \n5015  non-MAIT_cell  \n\n[5016 rows x 770 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>Sequences</th>\n      <th>MAIT_cell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.149587</td>\n      <td>-0.197047</td>\n      <td>-0.606274</td>\n      <td>0.246161</td>\n      <td>0.146642</td>\n      <td>-0.208196</td>\n      <td>0.247288</td>\n      <td>-0.079729</td>\n      <td>0.198015</td>\n      <td>-0.245093</td>\n      <td>...</td>\n      <td>-0.638298</td>\n      <td>0.011018</td>\n      <td>-0.319213</td>\n      <td>0.780746</td>\n      <td>-0.412318</td>\n      <td>0.522235</td>\n      <td>0.514297</td>\n      <td>0.207887</td>\n      <td>CASSVAGLLYEQYF</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.003837</td>\n      <td>0.004939</td>\n      <td>-0.305185</td>\n      <td>-0.467737</td>\n      <td>0.554620</td>\n      <td>0.526504</td>\n      <td>0.037872</td>\n      <td>-0.058776</td>\n      <td>0.078017</td>\n      <td>-0.378901</td>\n      <td>...</td>\n      <td>0.325271</td>\n      <td>-0.620283</td>\n      <td>-0.451306</td>\n      <td>-0.204477</td>\n      <td>-0.042363</td>\n      <td>0.488556</td>\n      <td>0.090419</td>\n      <td>0.102915</td>\n      <td>CASSHPPGADLGGQPQHF</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.027054</td>\n      <td>0.238266</td>\n      <td>0.138490</td>\n      <td>-0.477724</td>\n      <td>0.421007</td>\n      <td>0.106373</td>\n      <td>-0.682291</td>\n      <td>-0.285417</td>\n      <td>0.483916</td>\n      <td>-0.346199</td>\n      <td>...</td>\n      <td>0.507948</td>\n      <td>-0.131854</td>\n      <td>0.230915</td>\n      <td>0.139384</td>\n      <td>-0.132491</td>\n      <td>0.416187</td>\n      <td>0.232041</td>\n      <td>-0.580679</td>\n      <td>CAWSVPPVQGDRTQHF</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.149578</td>\n      <td>0.100374</td>\n      <td>-0.122322</td>\n      <td>-0.478098</td>\n      <td>0.454484</td>\n      <td>0.019130</td>\n      <td>0.048994</td>\n      <td>0.235329</td>\n      <td>0.132402</td>\n      <td>-0.505863</td>\n      <td>...</td>\n      <td>0.282709</td>\n      <td>0.410364</td>\n      <td>0.008110</td>\n      <td>-0.087051</td>\n      <td>-0.256943</td>\n      <td>0.420582</td>\n      <td>-0.317372</td>\n      <td>0.073733</td>\n      <td>CSARDLDSLTNGYTF</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.540540</td>\n      <td>0.291595</td>\n      <td>-0.353379</td>\n      <td>-0.261123</td>\n      <td>0.426946</td>\n      <td>0.357447</td>\n      <td>-0.488219</td>\n      <td>-0.435053</td>\n      <td>0.388957</td>\n      <td>-0.267924</td>\n      <td>...</td>\n      <td>0.328469</td>\n      <td>-0.103942</td>\n      <td>0.323352</td>\n      <td>0.735837</td>\n      <td>0.272375</td>\n      <td>0.473237</td>\n      <td>0.894415</td>\n      <td>-0.243902</td>\n      <td>CAWSGEPSQAQYF</td>\n      <td>MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5011</th>\n      <td>-0.329775</td>\n      <td>0.793744</td>\n      <td>-1.056300</td>\n      <td>0.181084</td>\n      <td>0.043187</td>\n      <td>-0.084797</td>\n      <td>0.497528</td>\n      <td>0.468565</td>\n      <td>0.060517</td>\n      <td>0.038454</td>\n      <td>...</td>\n      <td>-0.269269</td>\n      <td>-0.119622</td>\n      <td>-0.516974</td>\n      <td>0.407369</td>\n      <td>0.187545</td>\n      <td>0.344213</td>\n      <td>0.109828</td>\n      <td>0.269770</td>\n      <td>CASTGENNSPLHF</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>5012</th>\n      <td>-0.100326</td>\n      <td>0.304981</td>\n      <td>0.190182</td>\n      <td>-0.059698</td>\n      <td>0.107292</td>\n      <td>0.121101</td>\n      <td>-0.251405</td>\n      <td>-0.306332</td>\n      <td>0.125169</td>\n      <td>-0.237075</td>\n      <td>...</td>\n      <td>-0.172579</td>\n      <td>-0.399773</td>\n      <td>-0.378466</td>\n      <td>0.207969</td>\n      <td>-0.128755</td>\n      <td>0.727024</td>\n      <td>0.299680</td>\n      <td>0.027128</td>\n      <td>CASSVDWSGPGNTGELFF</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>5013</th>\n      <td>-0.056023</td>\n      <td>-0.094397</td>\n      <td>-0.433103</td>\n      <td>-0.062313</td>\n      <td>0.069507</td>\n      <td>-0.040174</td>\n      <td>0.057963</td>\n      <td>-0.075291</td>\n      <td>0.027573</td>\n      <td>-0.167322</td>\n      <td>...</td>\n      <td>-0.157909</td>\n      <td>0.064306</td>\n      <td>-0.047353</td>\n      <td>0.050179</td>\n      <td>-0.237840</td>\n      <td>0.765852</td>\n      <td>-0.496809</td>\n      <td>0.229118</td>\n      <td>CSARALAGGTNEQFF</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>5014</th>\n      <td>-0.422617</td>\n      <td>0.676036</td>\n      <td>-1.092209</td>\n      <td>0.034845</td>\n      <td>0.449366</td>\n      <td>0.100408</td>\n      <td>0.365332</td>\n      <td>0.275192</td>\n      <td>0.020950</td>\n      <td>0.030260</td>\n      <td>...</td>\n      <td>-0.000810</td>\n      <td>-0.096166</td>\n      <td>-0.774795</td>\n      <td>0.810294</td>\n      <td>-0.045002</td>\n      <td>0.009765</td>\n      <td>0.297485</td>\n      <td>0.518775</td>\n      <td>CASSFQGGDQPQHF</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n    <tr>\n      <th>5015</th>\n      <td>-0.679665</td>\n      <td>0.381582</td>\n      <td>-0.096865</td>\n      <td>-0.755159</td>\n      <td>0.349162</td>\n      <td>0.068600</td>\n      <td>-0.496824</td>\n      <td>-0.169834</td>\n      <td>0.225958</td>\n      <td>-0.460315</td>\n      <td>...</td>\n      <td>-0.035289</td>\n      <td>-0.299447</td>\n      <td>-0.159665</td>\n      <td>0.281305</td>\n      <td>-0.450529</td>\n      <td>0.594555</td>\n      <td>0.529679</td>\n      <td>-0.038543</td>\n      <td>CASSQDMGSPETQYF</td>\n      <td>non-MAIT_cell</td>\n    </tr>\n  </tbody>\n</table>\n<p>5016 rows × 770 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload and set data variables\n",
    "data_dir_to_classify = \"./CDR3_data/MAIT_cell_data_embeddings_8_datasets_embeddings.csv\"\n",
    "df_data_dir = \"./CDR3_data/MAIT_cell_data_embeddings_8_datasets_embeddings.csv\"\n",
    "output_path = \"./CDR3_data/MAIT_cell_data_embeddings_8_datasets_embeddings_pub_priv.csv\"\n",
    "df_for_classification = pd.read_csv(data_dir_to_classify)\n",
    "data_df = pd.read_csv(df_data_dir)\n",
    "df_for_classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop index column - if necessary\n",
    "# df_for_classification.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n0    -0.149587 -0.197047 -0.606274  0.246161  0.146642 -0.208196  0.247288   \n1    -0.003837  0.004939 -0.305185 -0.467737  0.554620  0.526504  0.037872   \n2     0.027054  0.238266  0.138490 -0.477724  0.421007  0.106373 -0.682291   \n3    -0.149578  0.100374 -0.122322 -0.478098  0.454484  0.019130  0.048994   \n4    -0.540540  0.291595 -0.353379 -0.261123  0.426946  0.357447 -0.488219   \n...        ...       ...       ...       ...       ...       ...       ...   \n5011 -0.329775  0.793744 -1.056300  0.181084  0.043187 -0.084797  0.497528   \n5012 -0.100326  0.304981  0.190182 -0.059698  0.107292  0.121101 -0.251405   \n5013 -0.056023 -0.094397 -0.433103 -0.062313  0.069507 -0.040174  0.057963   \n5014 -0.422617  0.676036 -1.092209  0.034845  0.449366  0.100408  0.365332   \n5015 -0.679665  0.381582 -0.096865 -0.755159  0.349162  0.068600 -0.496824   \n\n             7         8         9  ...       758       759       760  \\\n0    -0.079729  0.198015 -0.245093  ...  0.221753  0.178292 -0.638298   \n1    -0.058776  0.078017 -0.378901  ... -0.394406 -0.488040  0.325271   \n2    -0.285417  0.483916 -0.346199  ... -0.040932 -0.713956  0.507948   \n3     0.235329  0.132402 -0.505863  ... -0.385887 -0.625642  0.282709   \n4    -0.435053  0.388957 -0.267924  ...  0.051595 -0.938021  0.328469   \n...        ...       ...       ...  ...       ...       ...       ...   \n5011  0.468565  0.060517  0.038454  ...  0.523287 -0.355889 -0.269269   \n5012 -0.306332  0.125169 -0.237075  ...  0.001577 -0.410296 -0.172579   \n5013 -0.075291  0.027573 -0.167322  ... -0.025749 -0.564122 -0.157909   \n5014  0.275192  0.020950  0.030260  ...  0.410969  0.098768 -0.000810   \n5015 -0.169834  0.225958 -0.460315  ... -0.274555 -0.882894 -0.035289   \n\n           761       762       763       764       765       766       767  \n0     0.011018 -0.319213  0.780746 -0.412318  0.522235  0.514297  0.207887  \n1    -0.620283 -0.451306 -0.204477 -0.042363  0.488556  0.090419  0.102915  \n2    -0.131854  0.230915  0.139384 -0.132491  0.416187  0.232041 -0.580679  \n3     0.410364  0.008110 -0.087051 -0.256943  0.420582 -0.317372  0.073733  \n4    -0.103942  0.323352  0.735837  0.272375  0.473237  0.894415 -0.243902  \n...        ...       ...       ...       ...       ...       ...       ...  \n5011 -0.119622 -0.516974  0.407369  0.187545  0.344213  0.109828  0.269770  \n5012 -0.399773 -0.378466  0.207969 -0.128755  0.727024  0.299680  0.027128  \n5013  0.064306 -0.047353  0.050179 -0.237840  0.765852 -0.496809  0.229118  \n5014 -0.096166 -0.774795  0.810294 -0.045002  0.009765  0.297485  0.518775  \n5015 -0.299447 -0.159665  0.281305 -0.450529  0.594555  0.529679 -0.038543  \n\n[5016 rows x 768 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.149587</td>\n      <td>-0.197047</td>\n      <td>-0.606274</td>\n      <td>0.246161</td>\n      <td>0.146642</td>\n      <td>-0.208196</td>\n      <td>0.247288</td>\n      <td>-0.079729</td>\n      <td>0.198015</td>\n      <td>-0.245093</td>\n      <td>...</td>\n      <td>0.221753</td>\n      <td>0.178292</td>\n      <td>-0.638298</td>\n      <td>0.011018</td>\n      <td>-0.319213</td>\n      <td>0.780746</td>\n      <td>-0.412318</td>\n      <td>0.522235</td>\n      <td>0.514297</td>\n      <td>0.207887</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.003837</td>\n      <td>0.004939</td>\n      <td>-0.305185</td>\n      <td>-0.467737</td>\n      <td>0.554620</td>\n      <td>0.526504</td>\n      <td>0.037872</td>\n      <td>-0.058776</td>\n      <td>0.078017</td>\n      <td>-0.378901</td>\n      <td>...</td>\n      <td>-0.394406</td>\n      <td>-0.488040</td>\n      <td>0.325271</td>\n      <td>-0.620283</td>\n      <td>-0.451306</td>\n      <td>-0.204477</td>\n      <td>-0.042363</td>\n      <td>0.488556</td>\n      <td>0.090419</td>\n      <td>0.102915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.027054</td>\n      <td>0.238266</td>\n      <td>0.138490</td>\n      <td>-0.477724</td>\n      <td>0.421007</td>\n      <td>0.106373</td>\n      <td>-0.682291</td>\n      <td>-0.285417</td>\n      <td>0.483916</td>\n      <td>-0.346199</td>\n      <td>...</td>\n      <td>-0.040932</td>\n      <td>-0.713956</td>\n      <td>0.507948</td>\n      <td>-0.131854</td>\n      <td>0.230915</td>\n      <td>0.139384</td>\n      <td>-0.132491</td>\n      <td>0.416187</td>\n      <td>0.232041</td>\n      <td>-0.580679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.149578</td>\n      <td>0.100374</td>\n      <td>-0.122322</td>\n      <td>-0.478098</td>\n      <td>0.454484</td>\n      <td>0.019130</td>\n      <td>0.048994</td>\n      <td>0.235329</td>\n      <td>0.132402</td>\n      <td>-0.505863</td>\n      <td>...</td>\n      <td>-0.385887</td>\n      <td>-0.625642</td>\n      <td>0.282709</td>\n      <td>0.410364</td>\n      <td>0.008110</td>\n      <td>-0.087051</td>\n      <td>-0.256943</td>\n      <td>0.420582</td>\n      <td>-0.317372</td>\n      <td>0.073733</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.540540</td>\n      <td>0.291595</td>\n      <td>-0.353379</td>\n      <td>-0.261123</td>\n      <td>0.426946</td>\n      <td>0.357447</td>\n      <td>-0.488219</td>\n      <td>-0.435053</td>\n      <td>0.388957</td>\n      <td>-0.267924</td>\n      <td>...</td>\n      <td>0.051595</td>\n      <td>-0.938021</td>\n      <td>0.328469</td>\n      <td>-0.103942</td>\n      <td>0.323352</td>\n      <td>0.735837</td>\n      <td>0.272375</td>\n      <td>0.473237</td>\n      <td>0.894415</td>\n      <td>-0.243902</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5011</th>\n      <td>-0.329775</td>\n      <td>0.793744</td>\n      <td>-1.056300</td>\n      <td>0.181084</td>\n      <td>0.043187</td>\n      <td>-0.084797</td>\n      <td>0.497528</td>\n      <td>0.468565</td>\n      <td>0.060517</td>\n      <td>0.038454</td>\n      <td>...</td>\n      <td>0.523287</td>\n      <td>-0.355889</td>\n      <td>-0.269269</td>\n      <td>-0.119622</td>\n      <td>-0.516974</td>\n      <td>0.407369</td>\n      <td>0.187545</td>\n      <td>0.344213</td>\n      <td>0.109828</td>\n      <td>0.269770</td>\n    </tr>\n    <tr>\n      <th>5012</th>\n      <td>-0.100326</td>\n      <td>0.304981</td>\n      <td>0.190182</td>\n      <td>-0.059698</td>\n      <td>0.107292</td>\n      <td>0.121101</td>\n      <td>-0.251405</td>\n      <td>-0.306332</td>\n      <td>0.125169</td>\n      <td>-0.237075</td>\n      <td>...</td>\n      <td>0.001577</td>\n      <td>-0.410296</td>\n      <td>-0.172579</td>\n      <td>-0.399773</td>\n      <td>-0.378466</td>\n      <td>0.207969</td>\n      <td>-0.128755</td>\n      <td>0.727024</td>\n      <td>0.299680</td>\n      <td>0.027128</td>\n    </tr>\n    <tr>\n      <th>5013</th>\n      <td>-0.056023</td>\n      <td>-0.094397</td>\n      <td>-0.433103</td>\n      <td>-0.062313</td>\n      <td>0.069507</td>\n      <td>-0.040174</td>\n      <td>0.057963</td>\n      <td>-0.075291</td>\n      <td>0.027573</td>\n      <td>-0.167322</td>\n      <td>...</td>\n      <td>-0.025749</td>\n      <td>-0.564122</td>\n      <td>-0.157909</td>\n      <td>0.064306</td>\n      <td>-0.047353</td>\n      <td>0.050179</td>\n      <td>-0.237840</td>\n      <td>0.765852</td>\n      <td>-0.496809</td>\n      <td>0.229118</td>\n    </tr>\n    <tr>\n      <th>5014</th>\n      <td>-0.422617</td>\n      <td>0.676036</td>\n      <td>-1.092209</td>\n      <td>0.034845</td>\n      <td>0.449366</td>\n      <td>0.100408</td>\n      <td>0.365332</td>\n      <td>0.275192</td>\n      <td>0.020950</td>\n      <td>0.030260</td>\n      <td>...</td>\n      <td>0.410969</td>\n      <td>0.098768</td>\n      <td>-0.000810</td>\n      <td>-0.096166</td>\n      <td>-0.774795</td>\n      <td>0.810294</td>\n      <td>-0.045002</td>\n      <td>0.009765</td>\n      <td>0.297485</td>\n      <td>0.518775</td>\n    </tr>\n    <tr>\n      <th>5015</th>\n      <td>-0.679665</td>\n      <td>0.381582</td>\n      <td>-0.096865</td>\n      <td>-0.755159</td>\n      <td>0.349162</td>\n      <td>0.068600</td>\n      <td>-0.496824</td>\n      <td>-0.169834</td>\n      <td>0.225958</td>\n      <td>-0.460315</td>\n      <td>...</td>\n      <td>-0.274555</td>\n      <td>-0.882894</td>\n      <td>-0.035289</td>\n      <td>-0.299447</td>\n      <td>-0.159665</td>\n      <td>0.281305</td>\n      <td>-0.450529</td>\n      <td>0.594555</td>\n      <td>0.529679</td>\n      <td>-0.038543</td>\n    </tr>\n  </tbody>\n</table>\n<p>5016 rows × 768 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove Sequences column and MAIT_cell column in df_for_classification\n",
    "df_for_classification.drop(columns=[\"Sequences\", \"MAIT_cell\"], inplace=True)\n",
    "df_for_classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Convert the embeddings to PyTorch tensors and stack them\n",
    "embeddings_tensors = [torch.tensor(embedding) for embedding in df_for_classification.values]\n",
    "stack_tensor = torch.stack(embeddings_tensors, dim=0)\n",
    "stack_tensor = stack_tensor.float()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Load the trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# defining the network\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,128)\n",
    "        self.fc2 = nn.Linear(128,32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Load your saved model\n",
    "PATH = CLASSIFICATION_MODEL_PATH\n",
    "checkpoint = torch.load(PATH)\n",
    "# create model\n",
    "model = Net(df_for_classification.shape[1])\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (fc1): Linear(in_features=768, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=32, bias=True)\n  (fc3): Linear(in_features=32, out_features=1, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model parameters\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n ...]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model to make predictions on the input data\n",
    "with torch.no_grad():\n",
    "    predictions = model.forward(stack_tensor)\n",
    "\n",
    "binary_preds = torch.where(predictions > 0.5, torch.ones_like(predictions), torch.zeros_like(predictions))\n",
    "pred_list = [int(x) for sublist in binary_preds.tolist() for x in sublist]\n",
    "pred_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n0    -0.149587 -0.197047 -0.606274  0.246161  0.146642 -0.208196  0.247288   \n1    -0.003837  0.004939 -0.305185 -0.467737  0.554620  0.526504  0.037872   \n2     0.027054  0.238266  0.138490 -0.477724  0.421007  0.106373 -0.682291   \n3    -0.149578  0.100374 -0.122322 -0.478098  0.454484  0.019130  0.048994   \n4    -0.540540  0.291595 -0.353379 -0.261123  0.426946  0.357447 -0.488219   \n...        ...       ...       ...       ...       ...       ...       ...   \n5011 -0.329775  0.793744 -1.056300  0.181084  0.043187 -0.084797  0.497528   \n5012 -0.100326  0.304981  0.190182 -0.059698  0.107292  0.121101 -0.251405   \n5013 -0.056023 -0.094397 -0.433103 -0.062313  0.069507 -0.040174  0.057963   \n5014 -0.422617  0.676036 -1.092209  0.034845  0.449366  0.100408  0.365332   \n5015 -0.679665  0.381582 -0.096865 -0.755159  0.349162  0.068600 -0.496824   \n\n             7         8         9  ...       761       762       763  \\\n0    -0.079729  0.198015 -0.245093  ...  0.011018 -0.319213  0.780746   \n1    -0.058776  0.078017 -0.378901  ... -0.620283 -0.451306 -0.204477   \n2    -0.285417  0.483916 -0.346199  ... -0.131854  0.230915  0.139384   \n3     0.235329  0.132402 -0.505863  ...  0.410364  0.008110 -0.087051   \n4    -0.435053  0.388957 -0.267924  ... -0.103942  0.323352  0.735837   \n...        ...       ...       ...  ...       ...       ...       ...   \n5011  0.468565  0.060517  0.038454  ... -0.119622 -0.516974  0.407369   \n5012 -0.306332  0.125169 -0.237075  ... -0.399773 -0.378466  0.207969   \n5013 -0.075291  0.027573 -0.167322  ...  0.064306 -0.047353  0.050179   \n5014  0.275192  0.020950  0.030260  ... -0.096166 -0.774795  0.810294   \n5015 -0.169834  0.225958 -0.460315  ... -0.299447 -0.159665  0.281305   \n\n           764       765       766       767           Sequences  \\\n0    -0.412318  0.522235  0.514297  0.207887      CASSVAGLLYEQYF   \n1    -0.042363  0.488556  0.090419  0.102915  CASSHPPGADLGGQPQHF   \n2    -0.132491  0.416187  0.232041 -0.580679    CAWSVPPVQGDRTQHF   \n3    -0.256943  0.420582 -0.317372  0.073733     CSARDLDSLTNGYTF   \n4     0.272375  0.473237  0.894415 -0.243902       CAWSGEPSQAQYF   \n...        ...       ...       ...       ...                 ...   \n5011  0.187545  0.344213  0.109828  0.269770       CASTGENNSPLHF   \n5012 -0.128755  0.727024  0.299680  0.027128  CASSVDWSGPGNTGELFF   \n5013 -0.237840  0.765852 -0.496809  0.229118     CSARALAGGTNEQFF   \n5014 -0.045002  0.009765  0.297485  0.518775      CASSFQGGDQPQHF   \n5015 -0.450529  0.594555  0.529679 -0.038543     CASSQDMGSPETQYF   \n\n          MAIT_cell  Public_Private_Label  \n0         MAIT_cell                     1  \n1         MAIT_cell                     0  \n2         MAIT_cell                     0  \n3         MAIT_cell                     0  \n4         MAIT_cell                     0  \n...             ...                   ...  \n5011  non-MAIT_cell                     1  \n5012  non-MAIT_cell                     0  \n5013  non-MAIT_cell                     1  \n5014  non-MAIT_cell                     1  \n5015  non-MAIT_cell                     1  \n\n[5016 rows x 771 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n      <th>Sequences</th>\n      <th>MAIT_cell</th>\n      <th>Public_Private_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.149587</td>\n      <td>-0.197047</td>\n      <td>-0.606274</td>\n      <td>0.246161</td>\n      <td>0.146642</td>\n      <td>-0.208196</td>\n      <td>0.247288</td>\n      <td>-0.079729</td>\n      <td>0.198015</td>\n      <td>-0.245093</td>\n      <td>...</td>\n      <td>0.011018</td>\n      <td>-0.319213</td>\n      <td>0.780746</td>\n      <td>-0.412318</td>\n      <td>0.522235</td>\n      <td>0.514297</td>\n      <td>0.207887</td>\n      <td>CASSVAGLLYEQYF</td>\n      <td>MAIT_cell</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.003837</td>\n      <td>0.004939</td>\n      <td>-0.305185</td>\n      <td>-0.467737</td>\n      <td>0.554620</td>\n      <td>0.526504</td>\n      <td>0.037872</td>\n      <td>-0.058776</td>\n      <td>0.078017</td>\n      <td>-0.378901</td>\n      <td>...</td>\n      <td>-0.620283</td>\n      <td>-0.451306</td>\n      <td>-0.204477</td>\n      <td>-0.042363</td>\n      <td>0.488556</td>\n      <td>0.090419</td>\n      <td>0.102915</td>\n      <td>CASSHPPGADLGGQPQHF</td>\n      <td>MAIT_cell</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.027054</td>\n      <td>0.238266</td>\n      <td>0.138490</td>\n      <td>-0.477724</td>\n      <td>0.421007</td>\n      <td>0.106373</td>\n      <td>-0.682291</td>\n      <td>-0.285417</td>\n      <td>0.483916</td>\n      <td>-0.346199</td>\n      <td>...</td>\n      <td>-0.131854</td>\n      <td>0.230915</td>\n      <td>0.139384</td>\n      <td>-0.132491</td>\n      <td>0.416187</td>\n      <td>0.232041</td>\n      <td>-0.580679</td>\n      <td>CAWSVPPVQGDRTQHF</td>\n      <td>MAIT_cell</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.149578</td>\n      <td>0.100374</td>\n      <td>-0.122322</td>\n      <td>-0.478098</td>\n      <td>0.454484</td>\n      <td>0.019130</td>\n      <td>0.048994</td>\n      <td>0.235329</td>\n      <td>0.132402</td>\n      <td>-0.505863</td>\n      <td>...</td>\n      <td>0.410364</td>\n      <td>0.008110</td>\n      <td>-0.087051</td>\n      <td>-0.256943</td>\n      <td>0.420582</td>\n      <td>-0.317372</td>\n      <td>0.073733</td>\n      <td>CSARDLDSLTNGYTF</td>\n      <td>MAIT_cell</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.540540</td>\n      <td>0.291595</td>\n      <td>-0.353379</td>\n      <td>-0.261123</td>\n      <td>0.426946</td>\n      <td>0.357447</td>\n      <td>-0.488219</td>\n      <td>-0.435053</td>\n      <td>0.388957</td>\n      <td>-0.267924</td>\n      <td>...</td>\n      <td>-0.103942</td>\n      <td>0.323352</td>\n      <td>0.735837</td>\n      <td>0.272375</td>\n      <td>0.473237</td>\n      <td>0.894415</td>\n      <td>-0.243902</td>\n      <td>CAWSGEPSQAQYF</td>\n      <td>MAIT_cell</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5011</th>\n      <td>-0.329775</td>\n      <td>0.793744</td>\n      <td>-1.056300</td>\n      <td>0.181084</td>\n      <td>0.043187</td>\n      <td>-0.084797</td>\n      <td>0.497528</td>\n      <td>0.468565</td>\n      <td>0.060517</td>\n      <td>0.038454</td>\n      <td>...</td>\n      <td>-0.119622</td>\n      <td>-0.516974</td>\n      <td>0.407369</td>\n      <td>0.187545</td>\n      <td>0.344213</td>\n      <td>0.109828</td>\n      <td>0.269770</td>\n      <td>CASTGENNSPLHF</td>\n      <td>non-MAIT_cell</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5012</th>\n      <td>-0.100326</td>\n      <td>0.304981</td>\n      <td>0.190182</td>\n      <td>-0.059698</td>\n      <td>0.107292</td>\n      <td>0.121101</td>\n      <td>-0.251405</td>\n      <td>-0.306332</td>\n      <td>0.125169</td>\n      <td>-0.237075</td>\n      <td>...</td>\n      <td>-0.399773</td>\n      <td>-0.378466</td>\n      <td>0.207969</td>\n      <td>-0.128755</td>\n      <td>0.727024</td>\n      <td>0.299680</td>\n      <td>0.027128</td>\n      <td>CASSVDWSGPGNTGELFF</td>\n      <td>non-MAIT_cell</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5013</th>\n      <td>-0.056023</td>\n      <td>-0.094397</td>\n      <td>-0.433103</td>\n      <td>-0.062313</td>\n      <td>0.069507</td>\n      <td>-0.040174</td>\n      <td>0.057963</td>\n      <td>-0.075291</td>\n      <td>0.027573</td>\n      <td>-0.167322</td>\n      <td>...</td>\n      <td>0.064306</td>\n      <td>-0.047353</td>\n      <td>0.050179</td>\n      <td>-0.237840</td>\n      <td>0.765852</td>\n      <td>-0.496809</td>\n      <td>0.229118</td>\n      <td>CSARALAGGTNEQFF</td>\n      <td>non-MAIT_cell</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5014</th>\n      <td>-0.422617</td>\n      <td>0.676036</td>\n      <td>-1.092209</td>\n      <td>0.034845</td>\n      <td>0.449366</td>\n      <td>0.100408</td>\n      <td>0.365332</td>\n      <td>0.275192</td>\n      <td>0.020950</td>\n      <td>0.030260</td>\n      <td>...</td>\n      <td>-0.096166</td>\n      <td>-0.774795</td>\n      <td>0.810294</td>\n      <td>-0.045002</td>\n      <td>0.009765</td>\n      <td>0.297485</td>\n      <td>0.518775</td>\n      <td>CASSFQGGDQPQHF</td>\n      <td>non-MAIT_cell</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5015</th>\n      <td>-0.679665</td>\n      <td>0.381582</td>\n      <td>-0.096865</td>\n      <td>-0.755159</td>\n      <td>0.349162</td>\n      <td>0.068600</td>\n      <td>-0.496824</td>\n      <td>-0.169834</td>\n      <td>0.225958</td>\n      <td>-0.460315</td>\n      <td>...</td>\n      <td>-0.299447</td>\n      <td>-0.159665</td>\n      <td>0.281305</td>\n      <td>-0.450529</td>\n      <td>0.594555</td>\n      <td>0.529679</td>\n      <td>-0.038543</td>\n      <td>CASSQDMGSPETQYF</td>\n      <td>non-MAIT_cell</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5016 rows × 771 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add predictions to data_df\n",
    "data_df[label] = pred_list\n",
    "data_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# save labeled data\n",
    "data_df.to_csv(output_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
